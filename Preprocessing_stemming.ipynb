{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8Ql905rOmU8"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "id": "Jx6n841YPQCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "import os\n",
        "import nltk\n",
        "import re\n",
        "from nltk.stem import ISRIStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "YwFJjQ06PUHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(\"/content/test _no_label.csv\")\n",
        "train = pd.read_excel(\"/content/train.xlsx\")\n",
        "\n",
        "\n",
        "train.columns = ['text','sentiment']\n",
        "train_text = train['text']\n",
        "\n",
        "# print(train)\n",
        "# print(test)"
      ],
      "metadata": {
        "id": "QneW7-4APWbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = ISRIStemmer()\n",
        "def solve(word_list):\n",
        "    arabic_reg = re.compile('[\\u0600-\\u06FF]+')\n",
        "    arabic_words = [word for word in word_list if arabic_reg.fullmatch(word)]\n",
        "    stemmed_words = [stemmer.stem(word) for word in arabic_words]\n",
        "    return stemmed_words\n",
        "\n",
        "def remove_and_stemm(tokenized_corpus):\n",
        "    filtered_corpus = []\n",
        "    for tokenized_document in tokenized_corpus:\n",
        "        filtered_document = solve(tokenized_document)\n",
        "        filtered_corpus.append(filtered_document)\n",
        "    return filtered_corpus"
      ],
      "metadata": {
        "id": "k3IupaIHPYzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train = [word_tokenize(sentence) for sentence in train_text]\n",
        "\n",
        "stop_words_arabic = set(stopwords.words('arabic'))\n",
        "filtered_texttrain = [\n",
        "    [word for word in sentence if word not in stop_words_arabic]\n",
        "    for sentence in tokenized_train\n",
        "]\n",
        "\n",
        "resulttrain=remove_and_stemm(filtered_texttrain)\n",
        "\n",
        "cv=CountVectorizer()\n",
        "todoc = [\" \".join(doc) for doc in resulttrain]\n",
        "x=cv.fit_transform(todoc)\n",
        "feature_names = cv.get_feature_names_out()\n",
        "xarr= x.toarray()\n",
        "df = pd.DataFrame(xarr, columns=feature_names)\n",
        "\n",
        "dftrain = pd.DataFrame({\n",
        "    'review_description': resulttrain,\n",
        "    'rating':train['sentiment']\n",
        "})\n",
        "\n",
        "\n",
        "tokenized_test = [word_tokenize(sentence) for sentence in test['review_description']]\n",
        "\n",
        "filtered_texttest = [\n",
        "    [word for word in sentence if word not in stop_words_arabic]\n",
        "    for sentence in tokenized_test\n",
        "]\n",
        "\n",
        "resulttest=remove_and_stemm(filtered_texttest)\n",
        "dftest = pd.DataFrame({\n",
        "    'ID': test['ID'],\n",
        "    'review_description': resulttest\n",
        "})\n",
        "\n",
        "\n",
        "final=[]\n",
        "for i in resulttest:\n",
        "  sentcount=[]\n",
        "  for j in feature_names:\n",
        "    count = i.count(j)\n",
        "    sentcount.append(count)\n",
        "  final.append(sentcount)\n",
        "\n",
        "\n",
        "dftestcount = pd.DataFrame({\n",
        "    'review_description':final\n",
        "})\n"
      ],
      "metadata": {
        "id": "8OLCB9JePdZ2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}